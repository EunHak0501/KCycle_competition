# KCycle 경륜 데이터 분석 경진대회


- **우수상** ([2023년 KCycle 경륜 데이터 분석 경진대회](https://www.kcycle.or.kr/customerplaza/notice/20147))

---

## 프로젝트 구조

```text
KCycle_competition/
├── example.ipynb              
├── setup.py                  
├── pyproject.toml             
├── README.md                  
├── data/                      # 크롤링된 데이터 (CSV)
└── src/
    └── kcycle/
        ├── __init__.py
        ├── kcycle_race_crawler.py   # 출주표(입력) 크롤러
        ├── kcycle_result_crawler.py # 결과(정답) 크롤러
        └── loader.py                # 데이터 로드 유틸
```

> **Tip**: `pip install -e .` 로 패키지를 editable 모드로 설치하면 `kcycle` 모듈을 어디서든 import 할 수 있습니다.

---

## 1. 데이터 수집

`data/` 아래 명령으로 크롤링을 할 수 있습니다.

```bash
# 출주표(선수 정보) 크롤링 (2017~2025년)
python src/kcycle/kcycle_race_crawler.py   --years 2017-2025 --pause 0.5

# 결과(순위·배당) 크롤링 (2017~2025년)
python src/kcycle/kcycle_result_crawler.py --years 2017-2025 --pause 0.5
```

명령 실행 후에는 `data/` 에 아래 두 파일이 생성됩니다.

- `race_info.csv`  – 경주별 7명의 출주표·과거 성적
- `race_results.csv` – 경주 결과(1‒3착·배당)

---

## 2. 데이터 로드

```python
from kcycle.loader import load_data

train = load_data()
```

- 경주 단위(7명 → 1샘플)와 선수 단위 두 가지를 모두 실험

---

## 3. 모델링 & 평가 방법

| 구분         | 기존 방식 | **본 프로젝트**           |
| ---------- |-------|----------------------|
| **평가 단위**  | 선수 개별 | **경주 전체** (7명이 한 샘플) |
| **목표값**    | 1-3위내 입상 여부 | 1-3위내 입상 여부          |
| **데이터 증강** | 효과 없음 | **높은 성능 향상**         |

### 모델•지표

- **모델**: RandomForest, LightGBM, XGBoost, LogisticRegression
- **지표**: Accuracy, R², F1, **RaceAccuracy** (경주 단위 예측 정확도)

---

## 4. 결과
#### (단승 / 복승 / 삼복승)

### Accuracy

| Model              | default               | default + aug         | our                       | our + aug                         |
| ------------------ |-----------------------|-----------------------|---------------------------|-----------------------------------|
| RandomForest       | 0.880 / 0.780 / 0.722 | 0.880 / 0.777 / 0.719 | 0.889 / 0.791 / 0.744     | **0.891** / **0.794** / **0.748** |
| LGBM               | 0.879 / 0.781 / 0.723 | 0.881 / 0.781 / 0.720 | 0.888 / 0.792 / 0.734     | **0.892** / **0.794** / **0.738** |
| XGBoost            | 0.878 / 0.780 / 0.722 | 0.877 / 0.780 / 0.723 | 0.885 / **0.791** / 0.732 | **0.887** / 0.789 / **0.737**     |
| LogisticRegression | 0.866 / 0.768 / 0.723 | 0.865 / 0.768 / 0.723 | 0.875 / **0.791** / 0.748 | **0.878** / 0.789 / **0.749**     |

### R²

| Model              | default                | default + aug         | our                       | our + aug                         |
| ------------------ |------------------------|-----------------------|---------------------------|-----------------------------------|
| RandomForest       | 0.260 / 0.244 / 0.231  | 0.253 / 0.234 / 0.219 | 0.284 / 0.270 / 0.249     | **0.296** / **0.278** / **0.256** |
| LGBM               | 0.282 / 0.264 / 0.249  | 0.283 / 0.264 / 0.245 | 0.321 / 0.292 / 0.271     | **0.330** / **0.297** / **0.276** |
| XGBoost            | 0.274 / 0.262 / 0.246  | 0.275 / 0.259 / 0.246 | 0.305 / **0.288** / 0.251 | **0.317** / 0.281 / **0.272**     |
| LogisticRegression | 0.197 / 0.218 / 0.222  | 0.195 / 0.218 / 0.221 | 0.249 / 0.272 / 0.267     | **0.256** / **0.278** / **0.273** |

### F1

| Model              | default                | default + aug                 | our                           | our + aug                         |
| ------------------ |------------------------|-------------------------------|-------------------------------|-----------------------------------|
| RandomForest       | 0.477 / 0.578 / 0.672  | **0.497** / **0.581** / 0.678 | 0.434 / 0.552 / 0.673         | 0.464 / 0.562 / **0.679**         |
| LGBM               | 0.512 / 0.571 / 0.650  | 0.508 / 0.572 / 0.643         | 0.548 / 0.591 / 0.667         | **0.566** / **0.597** / **0.671** |
| XGBoost            | 0.501 / 0.563 / 0.647  | 0.462 / 0.566 / 0.650         | 0.526 / 0.588 / 0.664         | **0.548** / **0.589** / **0.672** |
| LogisticRegression | 0.534 / 0.583 / 0.666  | 0.534 / 0.584 / 0.667         | 0.587 / **0.637** / **0.701** | **0.598** / 0.629 / 0.700         |

### RaceAccuracy *(적중률)*

| Model              | default                       | default + aug             | our                       | our + aug                         |
| ------------------ |-------------------------------|---------------------------|---------------------------|-----------------------------------|
| RandomForest       | 0.593 / 0.317 / 0.264         | 0.592 / 0.309 / 0.261     | 0.593 / 0.330 / 0.255     | **0.598** / **0.331** / **0.274** |
| LGBM               | 0.592 / **0.330** / **0.266** | 0.587 / **0.330** / 0.262 | 0.582 / 0.315 / 0.263     | **0.595** / 0.321 / 0.248         |
| XGBoost            | 0.586 / 0.326 / 0.250         | 0.582 / 0.317 / **0.262** | 0.570 / **0.333** / 0.244 | **0.589** / 0.305 / 0.261         |
| LogisticRegression | **0.612** / 0.333 / 0.263     | 0.610 / 0.335 / 0.260     | 0.599 / 0.332 / 0.270     | 0.601 / **0.337** / **0.272**     |

---

## 5. 재현 방법

1. **데이터 수집**: 위의 크롤링 스크립트 실행
2. **환경 설치**:
   ```bash
   pip install -e . # 프로젝트 루트에서 실행
   ```
3. **분석/학습**: `example.ipynb` 참고

---
