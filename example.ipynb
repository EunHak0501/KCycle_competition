{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 데이터 로드",
   "id": "693d76f4ad5e4cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:28:42.729661Z",
     "start_time": "2025-04-25T10:28:38.203959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from kcycle.loader import load_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "train = load_data()\n",
    "\n",
    "print(train.shape)"
   ],
   "id": "2414392294b9ab7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137207, 45)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:29:44.276334Z",
     "start_time": "2025-04-25T10:29:39.724657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_race_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 드롭할 컬럼\n",
    "    drop_cols = [\n",
    "        # '날짜',\n",
    "        '경주시간', '이름', '기수', '훈련지',\n",
    "        '훈련동참자', '훈련내용', '훈련일수',\n",
    "        '최근3_장소일자', '최근2_장소일자', '최근1_장소일자'\n",
    "    ]\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # 광명에서 경주한 것만 필터링\n",
    "    df = df[df['경주지역'] == '광명'].reset_index(drop=True)\n",
    "\n",
    "    # 기어배수 처리\n",
    "    df['기어배수'] = df['기어배수'].astype(str).str.strip().str[:4]\n",
    "\n",
    "    # 200m 처리\n",
    "    df['200m'] = df['200m'].astype(str).str.replace('\"', '.', regex=False)\n",
    "\n",
    "    # 지표관련 변수 처리\n",
    "    cols = ['승률', '연대율', '삼연대율', '입상/출전', '선행', '젖히기', '추입', '마크']\n",
    "    for col in cols:\n",
    "        col_str = df[col].astype(str)\n",
    "\n",
    "        # 괄호 안쪽 데이터 사용\n",
    "        # inner = col_str.str.extract(r\"\\((.*?)\\)\")[0]\n",
    "        # df[col] = col_str.str.extract(r\"\\((.*?)\\)\")[0]\n",
    "        # df[col] = inner.fillna(col_str)\n",
    "\n",
    "        # 괄호 바깥쪽 데이터 사용\n",
    "        df[col] = col_str.str.replace(r\"\\(.*?\\)\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # '/'가 포함되어있는 변수 처리\n",
    "    # '입상/출전' 분리\n",
    "    ratio_split = df['입상/출전'].astype(str).str.extract(r\"(\\d+)/(\\d+)\")\n",
    "    df['입상'] = pd.to_numeric(ratio_split[0], errors='coerce')\n",
    "    df['출전'] = pd.to_numeric(ratio_split[1], errors='coerce')\n",
    "    df = df.drop(columns='입상/출전')\n",
    "\n",
    "    # '최근3순위' 계산 (소수) ('279/554' → 0.5036)\n",
    "    ratio_recent = df['최근3순위'].astype(str).str.extract(r\"(\\d+)/(\\d+)\")\n",
    "    a = pd.to_numeric(ratio_recent[0], errors='coerce')\n",
    "    b = pd.to_numeric(ratio_recent[1], errors='coerce')\n",
    "    df['최근3순위'] = a / b\n",
    "\n",
    "    # 등급조정, 현재와 이전 등급 분리\n",
    "    s = df['등급조정'].astype(str)\n",
    "    df['현재_등급'] = s.str.slice(5, 7)\n",
    "    df['이전_등급'] = s.str.slice(12, 14)\n",
    "    df = df.drop(columns='등급조정')\n",
    "\n",
    "    # 최근3득점: 광명과 종합 점수 분리\n",
    "    s = df['최근3득점'].astype(str)\n",
    "    gwang = s.str.extract(r\"\\(광명\\)\\s*([\\d.]+)\")[0]\n",
    "    jonghap = s.str.extract(r\"\\(종합\\)\\s*([\\d.]+)\")[0]\n",
    "    df['광명_3득점'] = pd.to_numeric(gwang, errors='coerce')\n",
    "    df['종합_3득점'] = pd.to_numeric(jonghap, errors='coerce')\n",
    "    df = df.drop(columns='최근3득점')\n",
    "\n",
    "    cols = [\n",
    "        '최근3_1일', '최근3_2일', '최근3_3일',\n",
    "        '최근2_1일', '최근2_2일', '최근2_3일',\n",
    "        '최근1_1일', '최근1_2일', '최근1_3일',\n",
    "        '금회_1일', '금회_2일', '금회_3일',\n",
    "    ]\n",
    "    for col in cols:\n",
    "        col_data = df[col].astype(str)\n",
    "        pattern = r'^(\\S{2})\\s*(\\d+)-(\\d+)(\\S?)'\n",
    "\n",
    "        extracted = col_data.str.extract(pattern)\n",
    "        # df[f'{col}_종류'] = extracted[0]\n",
    "        df[f'{col}_순위'] = pd.to_numeric(extracted[2], errors='coerce').clip(upper=7)\n",
    "        # df[f'{col}_전법'] = extracted[3]\n",
    "        df = df.drop(columns=col)\n",
    "\n",
    "    # 경주종류 단순화\n",
    "    mapping = {\n",
    "        '특선': '특선',\n",
    "        '특별특선': '특선',\n",
    "        '특선결승': '특선결승',\n",
    "        '특선준결': '특선결승',\n",
    "        '그랑프리결승': '특선결승',\n",
    "        '우수': '우수',\n",
    "        '우수결승': '우수결승',\n",
    "        '우수준결': '우수결승',\n",
    "        '선발': '선발',\n",
    "        '선발결승': '선발결승',\n",
    "        '선발준결': '선발결승',\n",
    "\n",
    "        '준결': '특선', # 준결 경기에는 S등급 선수들이 가장 많음\n",
    "        '특별': '우수', # 특별 경기에는 A등급 선수들이 가장 많음\n",
    "        '특우': '특선', # 특우 경기에는 S등급 선수들이 가장 많음\n",
    "        '특별우수': '우수',\n",
    "    }\n",
    "    df['경주종류'] = df['경주종류'].map(mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = clean_race_data(train)"
   ],
   "id": "47dc2432591bb58e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train, Valid, Test split",
   "id": "7c9c8e024babfd26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:29:44.591541Z",
     "start_time": "2025-04-25T10:29:44.307197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_train_test_by_race(df, test_size=0.2) -> (pd.DataFrame, pd.DataFrame):\n",
    "    # '경주' 단위로 train/test 분리 (한 경주에 속한 모든 선수는 같은 세트에 속하도록).\n",
    "    # 미래의 경주 데이터로 과거의 경주를 예측하지 않도록 shuffle은 X.\n",
    "\n",
    "    df = df.copy()\n",
    "    df['race_id'] = (\n",
    "        df['연도'].astype(str) + '_' +\n",
    "        df['회차'].astype(str) + '_' +\n",
    "        df['일차'].astype(str) + '_' +\n",
    "        df['경주번호']\n",
    "    )\n",
    "\n",
    "    unique_races = df['race_id'].drop_duplicates().tolist()\n",
    "    n = len(unique_races)\n",
    "    cutoff = int(n * (1 - test_size))\n",
    "\n",
    "    train_race_ids = set(unique_races[:cutoff])\n",
    "    test_race_ids  = set(unique_races[cutoff:])\n",
    "\n",
    "    train_df = df[df['race_id'].isin(train_race_ids)].drop(columns='race_id').reset_index(drop=True)\n",
    "    test_df  = df[df['race_id'].isin(test_race_ids )].drop(columns='race_id').reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train, val = split_train_test_by_race(train, test_size=0.2)\n",
    "val, test = split_train_test_by_race(val, test_size=0.5)"
   ],
   "id": "ec65324def7aac40",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Preprocessing",
   "id": "36198f85cac5e24e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:29:46.093814Z",
     "start_time": "2025-04-25T10:29:44.622555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_missing_value(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    # 선수가 속한 현재 등급의 평균으로 대체\n",
    "    train['200m'] = pd.to_numeric(train['200m'].replace('-', pd.NA), errors='coerce')\n",
    "    valid['200m'] = pd.to_numeric(valid['200m'].replace('-', pd.NA), errors='coerce')\n",
    "\n",
    "    group_means = train.groupby('현재_등급')['200m'].mean()\n",
    "    train['200m'] = train.apply(\n",
    "        lambda row: group_means[row['현재_등급']] if pd.isna(row['200m']) else row['200m'],\n",
    "        axis=1\n",
    "    )\n",
    "    valid['200m'] = valid.apply(\n",
    "        lambda row: group_means.get(row['현재_등급'], pd.NA) if pd.isna(row['200m']) else row['200m'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    group_means = train.groupby('현재_등급')['종합_3득점'].mean()\n",
    "    train['종합_3득점'] = train.apply(\n",
    "        lambda row: group_means[row['현재_등급']] if pd.isna(row['종합_3득점']) else row['종합_3득점'],\n",
    "        axis=1\n",
    "    )\n",
    "    valid['종합_3득점'] = valid.apply(\n",
    "        lambda row: group_means.get(row['현재_등급'], pd.NA) if pd.isna(row['종합_3득점']) else row['종합_3득점'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 최근 순위가 결측인 경우(후보, 결장 등), 입상하지 못한 것과 동일하게 대체\n",
    "    # 순위보다 입상여부, 입상을 했으면 몇등을 했는지가 중요하다고 판단\n",
    "    # 1,2,3 > 순위 / 4 > 미입상\n",
    "    cols = [\n",
    "        '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "        '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "        '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "        '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "    ]\n",
    "    train[cols] = train[cols].fillna(7).clip(upper=4)\n",
    "    valid[cols] = valid[cols].fillna(7).clip(upper=4)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def drop_constant_columns(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    nunique = train.nunique()\n",
    "    constant_cols = nunique[nunique == 1].index.tolist()\n",
    "\n",
    "    train = train.drop(columns=constant_cols)\n",
    "    valid = valid.drop(columns=constant_cols)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def drop_unused_columns(df):\n",
    "    cols_to_drop = [\n",
    "        '날짜', '연도', '회차', '일차', '경주번호',\n",
    "    ]\n",
    "\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "def encode_categorical(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    cat_cols = [\n",
    "        '경주종류', '번호', '현재_등급', '이전_등급',\n",
    "        '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "        '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "        '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "        '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "    ]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        valid[col] = encoder.transform(valid[col])\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def cast_features(df):\n",
    "    cols = [col for col in df.columns]\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "def all_process(train, valid):\n",
    "    train, valid = impute_missing_value(train, valid)\n",
    "    train, valid = drop_constant_columns(train, valid)\n",
    "    train, valid = drop_unused_columns(train), drop_unused_columns(valid)\n",
    "    train, valid = encode_categorical(train, valid)\n",
    "    train, valid = cast_features(train), cast_features(valid)\n",
    "    return train, valid\n",
    "\n",
    "train, val = all_process(train, val)"
   ],
   "id": "4811c82ad364ab79",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:29:46.154070Z",
     "start_time": "2025-04-25T10:29:46.140070Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_target(df, bet_type='복승'):\n",
    "    \"\"\"\n",
    "    bet_type:\n",
    "      - '삼복승': rank <= 3  →  target=1\n",
    "      - '복승':   rank <= 2  → target=1\n",
    "      - '단승':   rank == 1  → target=1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # 기준 등수 설정\n",
    "    if bet_type == '삼복승':\n",
    "        cutoff = 3\n",
    "        df['target'] = (df['rank'] <= cutoff).astype(int)\n",
    "    elif bet_type == '복승':\n",
    "        cutoff = 2\n",
    "        df['target'] = (df['rank'] <= cutoff).astype(int)\n",
    "    elif bet_type == '단승':\n",
    "        # ==1 일 때만 1\n",
    "        df['target'] = (df['rank'] == 1).astype(int)\n",
    "    else:\n",
    "        raise ValueError(f\"알 수 없는 bet_type: {bet_type!r}. ('단승','복승','삼복승' 중 하나)\")\n",
    "\n",
    "    df = df.drop(columns=['rank'])\n",
    "\n",
    "    return df"
   ],
   "id": "bca9053e73565b39",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T10:29:51.596037Z",
     "start_time": "2025-04-25T10:29:51.583037Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Augmentation\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "def shuffle_fixed_block(\n",
    "    data: pd.DataFrame,\n",
    "    per_race: int,\n",
    "    ratio: float,\n",
    "    exclude_back_no_list: list[int] = None,\n",
    "    random_seed: int = None,\n",
    "    n_jobs: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    고정 크기 블록(per_race) 단위로 데이터프레임을 샘플링·셔플합니다.\n",
    "    필요하면 특정 BACK_NO 값들은 섞지 않고 원위치에 고정시킬 수 있으며,\n",
    "    n_jobs로 병렬 처리도 지원합니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        입력 데이터. 행 순서대로 per_race씩 블록화됩니다.\n",
    "    per_race : int\n",
    "        한 블록(경주)당 행(샘플) 수.\n",
    "    ratio : float\n",
    "        전체 블록 중 몇 %를 무작위로 추출해 처리할지 (0.0 ~ 1.0).\n",
    "    exclude_back_no_list : list of int, optional\n",
    "        이 BACK_NO 값들에 해당하는 행들은 섞지 않고 원위치에 둡니다.\n",
    "    random_seed : int, optional\n",
    "        랜덤 시드(재현성 확보).\n",
    "    n_jobs : int, default=1\n",
    "        그룹 단위 셔플을 몇 개의 프로세스로 병렬 실행할지.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        선택된 블록만 섞은 뒤 합쳐서 반환합니다. RACE_ID 컬럼은 삭제됩니다.\n",
    "    \"\"\"\n",
    "    # 1) 랜덤 시드 고정\n",
    "    if random_seed is not None:\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "    # 2) RACE_ID 생성 (고정 크기 블록)\n",
    "    df = data.copy()\n",
    "    df['RACE_ID'] = np.arange(len(df)) // per_race\n",
    "\n",
    "    # 3) 블록 샘플링\n",
    "    race_ids = df['RACE_ID'].unique()\n",
    "    n_select = int(len(race_ids) * ratio)\n",
    "    selected_ids = np.random.choice(race_ids, n_select, replace=False)\n",
    "    df_sampled = df[df['RACE_ID'].isin(selected_ids)]\n",
    "\n",
    "    # 4) 그룹별 처리 함수 정의\n",
    "    def _shuffle_group(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        gl = group.reset_index(drop=True)\n",
    "        # 제외할 로컬 인덱스 계산\n",
    "        if exclude_back_no_list:\n",
    "            excl_pos = gl[gl['번호'].isin(exclude_back_no_list)].index.tolist()\n",
    "        else:\n",
    "            excl_pos = []\n",
    "        # 나머지 행들만 완전 셔플\n",
    "        rest = gl.drop(index=excl_pos)\n",
    "        rest_shuffled = rest.sample(frac=1.0, random_state=random_seed).reset_index(drop=True)\n",
    "        # 빈 슬롯(로컬 인덱스)\n",
    "        slots = [i for i in range(per_race) if i not in excl_pos]\n",
    "        # 새 그룹 생성\n",
    "        new_gl = gl.copy()\n",
    "        for i, slot in enumerate(slots):\n",
    "            new_gl.iloc[slot] = rest_shuffled.iloc[i]\n",
    "        return new_gl\n",
    "\n",
    "    # 5) 병렬 혹은 순차 처리\n",
    "    groups = [grp for _, grp in df_sampled.groupby('RACE_ID')]\n",
    "    if n_jobs == 1:\n",
    "        shuffled = [_shuffle_group(g) for g in groups]\n",
    "    else:\n",
    "        shuffled = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(_shuffle_group)(g) for g in groups\n",
    "        )\n",
    "\n",
    "    # 6) 결과 합치고 정리\n",
    "    result = pd.concat(shuffled, ignore_index=True)\n",
    "    return result.drop(columns=['RACE_ID'])\n",
    "\n",
    "\n",
    "def reverse_fixed_block(\n",
    "    data: pd.DataFrame,\n",
    "    per_race: int,\n",
    "    ratio: float,\n",
    "    n_jobs: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    고정 크기 블록(per_race) 단위로 순서를 뒤집어 샘플링합니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        입력 데이터. 행 순서대로 per_race씩 블록화됩니다.\n",
    "    per_race : int\n",
    "        한 블록(경주)당 행(샘플) 수.\n",
    "    ratio : float\n",
    "        전체 블록 중 몇 %를 무작위로 선택해 순서를 뒤집을지 (0.0 ~ 1.0).\n",
    "    n_jobs : int, default=1\n",
    "        블록 단위 처리를 몇 개의 프로세스로 병렬 실행할지.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        선택된 블록만 순서를 뒤집어 합쳐서 반환합니다. RACE_ID 컬럼은 삭제됩니다.\n",
    "    \"\"\"\n",
    "    # 1) 랜덤 시드 고정\n",
    "\n",
    "    # 2) RACE_ID 생성 (고정 크기 블록)\n",
    "    df = data.copy()\n",
    "    df['RACE_ID'] = np.arange(len(df)) // per_race\n",
    "\n",
    "    # 3) 블록 샘플링\n",
    "    race_ids = df['RACE_ID'].unique()\n",
    "    n_select = int(len(race_ids) * ratio)\n",
    "    selected_ids = np.random.choice(race_ids, n_select, replace=False)\n",
    "    df_sampled = df[df['RACE_ID'].isin(selected_ids)]\n",
    "\n",
    "    # 4) 그룹별 뒤집기 함수\n",
    "    def _reverse_group(group: pd.DataFrame) -> pd.DataFrame:\n",
    "        gl = group.reset_index(drop=True)\n",
    "        return gl.iloc[::-1]\n",
    "\n",
    "    # 5) 병렬 또는 순차 처리\n",
    "    groups = [grp for _, grp in df_sampled.groupby('RACE_ID')]\n",
    "    if n_jobs == 1:\n",
    "        reversed_groups = [_reverse_group(g) for g in groups]\n",
    "    else:\n",
    "        reversed_groups = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(_reverse_group)(g) for g in groups\n",
    "        )\n",
    "\n",
    "    # 6) 결과 합치고 정리\n",
    "    result = pd.concat(reversed_groups, ignore_index=True)\n",
    "    return result.drop(columns=['RACE_ID'])"
   ],
   "id": "9e8afe9a6594ff69",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:50:42.424697Z",
     "start_time": "2025-04-25T12:50:25.728530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = load_data()\n",
    "train = clean_race_data(train)\n",
    "train, val = split_train_test_by_race(train, test_size=0.2)\n",
    "val, test = split_train_test_by_race(val, test_size=0.5)\n",
    "train_ = train.copy()\n",
    "\n",
    "train, val = all_process(train, val)\n",
    "_, test = all_process(train_, test)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ],
   "id": "8baa28f9a4bba313",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88368, 32) (11046, 32) (11046, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:53:01.581149Z",
     "start_time": "2025-04-25T12:52:47.353039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 필요시 증강\n",
    "\n",
    "train_augmented_shuffle = shuffle_fixed_block(\n",
    "    train, per_race=7, ratio=0.5, exclude_back_no_list=[3], random_seed=42, n_jobs=12,\n",
    ")\n",
    "train_augmented_reverse = reverse_fixed_block(\n",
    "    train, per_race=7, ratio=0.5, n_jobs=12,\n",
    ")\n",
    "\n",
    "print(f'기존 학습 데이터: {train.shape[0]}, 증강한 데이터: {train_augmented_shuffle.shape[0]} + {train_augmented_reverse.shape[0]}')\n",
    "\n",
    "n_aug = len(train_augmented_shuffle)\n",
    "train_augmented_shuffle['번호'] = train['번호'].iloc[:n_aug].values\n",
    "\n",
    "n_aug = len(train_augmented_reverse)\n",
    "train_augmented_reverse['번호'] = train['번호'].iloc[:n_aug].values\n",
    "\n",
    "train = pd.concat([train, train_augmented_shuffle, train_augmented_reverse], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "print(f'최종 학습 데이터: {train.shape[0]}개')"
   ],
   "id": "3aafd972950fab6f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 학습 데이터: 88368, 증강한 데이터: 44184 + 44184\n",
      "최종 학습 데이터: 176736개\n"
     ]
    }
   ],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:53:04.958346Z",
     "start_time": "2025-04-25T12:53:04.829347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "bet_type = '삼복승'  # 단승, 복승, 삼복승\n",
    "\n",
    "if bet_type=='단승':\n",
    "    top_k = 1\n",
    "elif bet_type=='복승':\n",
    "    top_k = 2\n",
    "elif bet_type=='삼복승':\n",
    "    top_k = 3\n",
    "\n",
    "train = add_target(train, bet_type=bet_type)\n",
    "val = add_target(val, bet_type=bet_type)\n",
    "test = add_target(test, bet_type=bet_type)"
   ],
   "id": "c3baf4a95c124b32",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training",
   "id": "a338962538e0755c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:57:27.930630Z",
     "start_time": "2025-04-25T12:57:24.890214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "X_val = val.drop(columns=['target'])\n",
    "X_test = test.drop(columns=['target'])\n",
    "\n",
    "y_train = train['target']\n",
    "y_val = val['target']\n",
    "y_test = test['target']\n",
    "\n",
    "cat_cols = [\n",
    "    '경주종류', '번호', '현재_등급', '이전_등급',\n",
    "    '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "    '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "    '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "    '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "]\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('category')\n",
    "X_val[cat_cols] = X_val[cat_cols].astype('category')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('category')\n",
    "\n",
    "### Random Forest\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "###\n",
    "\n",
    "### LightGBM\n",
    "# model = LGBMClassifier(\n",
    "#     n_estimators=5000,\n",
    "#     random_state=42,\n",
    "#     enable_categorical=True,\n",
    "#     early_stopping_rounds=100,\n",
    "#     verbose=-1,\n",
    "# )\n",
    "# model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=(X_val, y_val),\n",
    "#     categorical_feature=cat_cols\n",
    "# )\n",
    "###\n",
    "\n",
    "### XGBoost\n",
    "# model = XGBClassifier(\n",
    "#     n_estimators=5000,\n",
    "#     random_state=42,\n",
    "#     enable_categorical=True,\n",
    "#     early_stopping_rounds=100,\n",
    "# )\n",
    "# model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=[(X_val, y_val)],\n",
    "#     verbose=0,\n",
    "# )\n",
    "###\n",
    "\n",
    "### Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    ")\n",
    "###\n",
    "\n",
    "y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]"
   ],
   "id": "79a92d799c79224d",
   "outputs": [],
   "execution_count": 168
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "ebf53d04e989976a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 개별 지표",
   "id": "184a37cfbf13db69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:57:31.234387Z",
     "start_time": "2025-04-25T12:57:30.984256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train set metrics\n",
    "train_accuracy = accuracy_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Validation set metrics \n",
    "val_accuracy = accuracy_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Test set metrics\n",
    "test_accuracy = accuracy_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Train': [train_accuracy, train_auc, train_f1, train_r2],\n",
    "    'Validation': [val_accuracy, val_auc, val_f1, val_r2],\n",
    "    'Test': [test_accuracy, test_auc, test_f1, test_r2]\n",
    "}, index=['Accuracy', 'AUC', 'F1', 'R2'])\n",
    "\n",
    "metrics_df.round(3)"
   ],
   "id": "bef31e179295708",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Train  Validation   Test\n",
       "Accuracy  0.742       0.716  0.723\n",
       "AUC       0.799       0.782  0.790\n",
       "F1        0.678       0.660  0.667\n",
       "R2        0.273       0.195  0.221"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.742</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.799</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.678</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.273</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 169
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 경주별 지표",
   "id": "7e6c37eb75846287"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:57:59.786643Z",
     "start_time": "2025-04-25T12:57:59.765643Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reshape_by_race(arr: np.ndarray, per_race: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    - 1D 배열 (n_samples,)   → (n_races, per_race)\n",
    "    - 2D 배열 (n_samples, f) → (n_races, per_race * f)\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "\n",
    "    # 1D\n",
    "    if arr.ndim == 1:\n",
    "        total = arr.size\n",
    "        if total % per_race != 0:\n",
    "            raise ValueError(f\"배열 길이({total})가 per_race({per_race})의 배수가 아닙니다.\")\n",
    "        return arr.reshape(-1, per_race)\n",
    "\n",
    "    # 2D\n",
    "    elif arr.ndim == 2:\n",
    "        n_samples, n_features = arr.shape\n",
    "        if n_samples % per_race != 0:\n",
    "            raise ValueError(f\"첫 번째 축 길이({n_samples})가 per_race({per_race})의 배수가 아닙니다.\")\n",
    "        n_races = n_samples // per_race\n",
    "        # per_race 개의 샘플 × n_features를 한 축으로 합침\n",
    "        return arr.reshape(n_races, per_race * n_features)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"지원하지 않는 차원(ndim={arr.ndim})입니다. 1D 또는 2D만 처리 가능합니다.\")\n",
    "\n",
    "# y_test 배열을 (N,)에서 (N/7, 7)로 변환\n",
    "y_train_race = reshape_by_race(y_train, per_race=7)\n",
    "y_train_pred_race = reshape_by_race(y_train_pred, per_race=7)\n",
    "\n",
    "y_val_race = reshape_by_race(y_val, per_race=7)\n",
    "y_val_pred_race = reshape_by_race(y_val_pred, per_race=7)\n",
    "\n",
    "y_test_race = reshape_by_race(y_test, per_race=7)\n",
    "y_test_pred_race = reshape_by_race(y_test_pred, per_race=7)\n",
    "\n",
    "print(y_train_race.shape, y_train_pred_race.shape)\n",
    "print(y_val_race.shape, y_val_pred_race.shape)\n",
    "print(y_test_race.shape, y_test_pred_race.shape)"
   ],
   "id": "1712ca4a1f488ac4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25248, 7) (25248, 7)\n",
      "(1578, 7) (1578, 7)\n",
      "(1578, 7) (1578, 7)\n"
     ]
    }
   ],
   "execution_count": 170
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T12:58:01.513683Z",
     "start_time": "2025-04-25T12:58:01.388683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_race_metrics(\n",
    "    y_true: np.ndarray,\n",
    "    y_score: np.ndarray,\n",
    "    threshold: float = 0.5,\n",
    "    top_k: int = 2\n",
    ") -> pd.Series:\n",
    "    \"\"\"\n",
    "    경주별 multi‐label 지표를 계산합니다.\n",
    "    입력 y_true, y_score는 각각 (n_races, n_classes) 형태여야 합니다.\n",
    "\n",
    "    race_accuracy는 per‐race 내 top_k만 positive로 간주했을 때,\n",
    "    그 이진 예측이 true label과 완전히 일치한 레이스의 비율입니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape (n_races, n_classes)\n",
    "        실제 binary 타깃 매트릭스 (0/1).\n",
    "    y_score : array-like, shape (n_races, n_classes)\n",
    "        예측 점수(확률) 매트릭스.\n",
    "    threshold : float, default=0.5\n",
    "        multi‐label 지표를 위한 이진화 기준.\n",
    "    top_k : int, default=2\n",
    "        race_accuracy 계산 시 per‐race 내 상위 k개만 positive로 간주.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        {\n",
    "            \"race_accuracy\": float\n",
    "        }\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_score = np.asarray(y_score)\n",
    "    if y_true.shape != y_score.shape:\n",
    "        raise ValueError(f\"y_true.shape {y_true.shape}와 y_score.shape {y_score.shape}가 일치해야 합니다.\")\n",
    "    if y_true.ndim != 2:\n",
    "        raise ValueError(f\"입력 배열은 2D여야 합니다. (현재 ndim={y_true.ndim})\")\n",
    "\n",
    "    # 1) threshold 기반 이진화 (multi‐label 지표용)\n",
    "    y_pred_thr = (y_score > threshold).astype(int)\n",
    "\n",
    "    # 2) top_k 기반 이진화 (race_accuracy용)\n",
    "    n_races, n_classes = y_score.shape\n",
    "    y_pred_topk = np.zeros_like(y_pred_thr, dtype=int)\n",
    "    for i in range(n_races):\n",
    "        # 상위 k개 인덱스\n",
    "        top_idx = np.argsort(y_score[i])[-top_k:]\n",
    "        y_pred_topk[i, top_idx] = 1\n",
    "\n",
    "    # 3) race_accuracy: per‐race 내 top_k 예측이 true와 완전 일치한 비율\n",
    "    race_acc = np.mean(np.all(y_true == y_pred_topk, axis=1))\n",
    "\n",
    "    return pd.Series({\"race_accuracy\": race_acc})\n",
    "\n",
    "\n",
    "# 단승: top_k=1, 복승:top_k=2, 삼복승:top_k=3\n",
    "train_metrics = compute_race_metrics(y_train_race, y_train_pred_race, top_k=top_k)\n",
    "val_metrics   = compute_race_metrics(y_val_race, y_val_pred_race, top_k=top_k)\n",
    "test_metrics  = compute_race_metrics(y_test_race, y_test_pred_race, top_k=top_k)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Train\": train_metrics,\n",
    "    \"Validation\": val_metrics,\n",
    "    \"Test\": test_metrics\n",
    "})\n",
    "\n",
    "metrics_df.round(3)"
   ],
   "id": "3d2edcfcd92f8b29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Train  Validation  Test\n",
       "race_accuracy  0.304       0.264  0.26"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race_accuracy</th>\n",
       "      <td>0.304</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 171
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 경주인 것을 고려한 모델링",
   "id": "2c3de820adcdb6b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:18.968031Z",
     "start_time": "2025-04-25T13:07:59.605605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = load_data()\n",
    "train = clean_race_data(train)\n",
    "train, val = split_train_test_by_race(train, test_size=0.2)\n",
    "val, test = split_train_test_by_race(val, test_size=0.5)\n",
    "train_ = train.copy()\n",
    "\n",
    "train, val = all_process(train, val)\n",
    "_, test = all_process(train_, test)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ],
   "id": "2c7f5aca4588a2b7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88368, 32) (11046, 32) (11046, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_3280\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:33.762271Z",
     "start_time": "2025-04-25T13:08:19.104038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## 필요시 증강\n",
    "\n",
    "# 3번 라인을 제외하고 shuffle\n",
    "train_augmented_shuffle = shuffle_fixed_block(\n",
    "    train, per_race=7, ratio=0.5, exclude_back_no_list=[3], random_seed=42, n_jobs=12,\n",
    ")\n",
    "\n",
    "# 1번부터 7번까지의 순서를 뒤집음(3번 라인은 그대로)\n",
    "train_augmented_reverse = reverse_fixed_block(\n",
    "    train, per_race=7, ratio=0.5, n_jobs=12,\n",
    ")\n",
    "\n",
    "print(f'기존 학습 데이터: {train.shape[0]}, 증강한 데이터: {train_augmented_shuffle.shape[0]} + {train_augmented_reverse.shape[0]}')\n",
    "\n",
    "n_aug = len(train_augmented_shuffle)\n",
    "train_augmented_shuffle['번호'] = train['번호'].iloc[:n_aug].values\n",
    "\n",
    "n_aug = len(train_augmented_reverse)\n",
    "train_augmented_reverse['번호'] = train['번호'].iloc[:n_aug].values\n",
    "\n",
    "train = pd.concat([train, train_augmented_shuffle, train_augmented_reverse], ignore_index=True).reset_index(drop=True)\n",
    "\n",
    "print(f'최종 학습 데이터: {train.shape[0]}개')"
   ],
   "id": "1496cb042dbc1100",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 학습 데이터: 88368, 증강한 데이터: 44184 + 44184\n",
      "최종 학습 데이터: 176736개\n"
     ]
    }
   ],
   "execution_count": 205
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:34.153511Z",
     "start_time": "2025-04-25T13:08:33.908627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# '번호' 컬럼은 reshape하면서 번호에 맞게 위치가 고정되므로 drop\n",
    "train = train.drop(columns=['번호'])\n",
    "val = val.drop(columns=['번호'])\n",
    "test = test.drop(columns=['번호'])\n",
    "\n",
    "print(train.shape, val.shape, test.shape)\n",
    "\n",
    "bet_type = '삼복승'  # 단승, 복승, 삼복승\n",
    "\n",
    "if bet_type=='단승':\n",
    "    top_k = 1\n",
    "elif bet_type=='복승':\n",
    "    top_k = 2\n",
    "elif bet_type=='삼복승':\n",
    "    top_k = 3\n",
    "\n",
    "train = add_target(train, bet_type=bet_type)\n",
    "val = add_target(val, bet_type=bet_type)\n",
    "test = add_target(test, bet_type=bet_type)"
   ],
   "id": "2684923a0271fb6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176736, 31) (11046, 31) (11046, 31)\n"
     ]
    }
   ],
   "execution_count": 206
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:34.664038Z",
     "start_time": "2025-04-25T13:08:34.286510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "X_val = val.drop(columns=['target'])\n",
    "X_test = test.drop(columns=['target'])\n",
    "\n",
    "y_train = train['target']\n",
    "y_val = val['target']\n",
    "y_test = test['target']\n",
    "\n",
    "cat_cols = [\n",
    "    '경주종류', '현재_등급', '이전_등급',\n",
    "    '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "    '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "    '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "    '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "]\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('category')\n",
    "X_val[cat_cols] = X_val[cat_cols].astype('category')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('category')\n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)\n",
    "\n",
    "X_train_race = reshape_by_race(X_train, per_race=7)\n",
    "X_val_race = reshape_by_race(X_val, per_race=7)\n",
    "X_test_race = reshape_by_race(X_test, per_race=7)\n",
    "\n",
    "y_train_race = reshape_by_race(y_train, per_race=7)\n",
    "y_val_race = reshape_by_race(y_val, per_race=7)\n",
    "y_test_race = reshape_by_race(y_test, per_race=7)\n",
    "\n",
    "print(X_train_race.shape, X_val_race.shape, X_test_race.shape)"
   ],
   "id": "833b80805b854fc3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176736, 30) (11046, 30) (11046, 30)\n",
      "(25248, 210) (1578, 210) (1578, 210)\n"
     ]
    }
   ],
   "execution_count": 207
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:34.829071Z",
     "start_time": "2025-04-25T13:08:34.795035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# per_race 값 (reshape_by_race에 사용한 것과 동일해야 합니다)\n",
    "per_race = 7\n",
    "\n",
    "# 전체 피처 수\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "# 1) 원본 DataFrame에서 각 cat_cols의 컬럼 인덱스 추출\n",
    "orig_cat_idx = [X_train.columns.get_loc(col) for col in cat_cols]\n",
    "\n",
    "# 2) per_race 블록별로 오프셋을 더해서 모든 인덱스 생성\n",
    "cat_feature_indices = [\n",
    "    block * n_features + idx\n",
    "    for block in range(per_race)\n",
    "    for idx in orig_cat_idx\n",
    "]\n",
    "\n",
    "cat_feature_indices = sorted(cat_feature_indices)\n",
    "print(cat_feature_indices)"
   ],
   "id": "92bdabe090e525cf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 44, 45, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 104, 105, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 134, 135, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 194, 195, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209]\n"
     ]
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:08:34.994074Z",
     "start_time": "2025-04-25T13:08:34.958072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "\n",
    "class MultiOutputClassifierCustom(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, **fit_kwargs):\n",
    "        \"\"\"\n",
    "        각 출력(y[:, i])마다 estimator를 복제하여 학습합니다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        y : array-like, shape (n_samples,) or (n_samples, n_outputs)\n",
    "        eval_set : list of (X_val, y_val) tuples, optional\n",
    "            모든 타깃에 공통으로 사용할 검증용 데이터. 각 y_val은 1D 또는 2D여도 무방하며,\n",
    "            내부에서 타깃별로 분리되어 전달됩니다.\n",
    "        **fit_kwargs : dict\n",
    "            estimator.fit에 추가로 전달할 인자들 (예: early_stopping_rounds, eval_metric 등)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        y = np.asarray(y)\n",
    "        if y.ndim == 1:\n",
    "            y = y.reshape(-1, 1)\n",
    "\n",
    "        # 준비된 eval_set이 있으면, 타깃별로 분리\n",
    "        if eval_set is not None:\n",
    "            # eval_set 내부의 y_val 배열도 numpy로\n",
    "            eval_sets_per_output = []\n",
    "            for i in range(y.shape[1]):\n",
    "                single_output_sets = []\n",
    "                for X_val, y_val in eval_set:\n",
    "                    y_val = np.asarray(y_val)\n",
    "                    # 1D → 2D면, 각 열 i 분리\n",
    "                    if y_val.ndim == 2:\n",
    "                        y_val_i = y_val[:, i]\n",
    "                    else:\n",
    "                        y_val_i = y_val\n",
    "                    single_output_sets.append((X_val, y_val_i))\n",
    "                eval_sets_per_output.append(single_output_sets)\n",
    "        else:\n",
    "            eval_sets_per_output = [None] * y.shape[1]\n",
    "\n",
    "        self.estimators_ = []\n",
    "        for i in range(y.shape[1]):\n",
    "            est = clone(self.estimator)\n",
    "            # 이 타깃에만 해당하는 eval_set\n",
    "            params = fit_kwargs.copy()\n",
    "            if eval_sets_per_output[i] is not None:\n",
    "                params['eval_set'] = eval_sets_per_output[i]\n",
    "            est.fit(X, y[:, i], **params)\n",
    "            self.estimators_.append(est)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        학습된 각 estimator로부터 예측(label)을 얻어 합칩니다.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        preds : ndarray, shape (n_samples, n_outputs)\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        # [(n_samples,), ...] → (n_outputs, n_samples)\n",
    "        preds = [est.predict(X) for est in self.estimators_]\n",
    "        return np.vstack(preds).T\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        학습된 각 estimator의 predict_proba에서 클래스=1 확률만 추출하여 합칩니다.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        probas : ndarray, shape (n_samples, n_outputs)\n",
    "            probas[i, j]는 i번째 샘플의 j번째 타깃이 1일 확률\n",
    "        \"\"\"\n",
    "        X = np.asarray(X)\n",
    "        probas = []\n",
    "        for est in self.estimators_:\n",
    "            p = est.predict_proba(X)\n",
    "            # binary classifier라면 p.shape = (n_samples, 2)\n",
    "            if p.shape[1] != 2:\n",
    "                raise ValueError(\"각 estimator는 이진 분류를 지원해야 합니다.\")\n",
    "            probas.append(p[:, 1])\n",
    "        # [(n_samples,), ...] → (n_outputs, n_samples) → transpose\n",
    "        return np.vstack(probas).T"
   ],
   "id": "7c4c8ba8e4a85a06",
   "outputs": [],
   "execution_count": 209
  },
  {
   "cell_type": "code",
   "id": "940c9c96-b23a-48f4-9a07-3c9690bd4554",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:17:22.850461Z",
     "start_time": "2025-04-25T13:17:08.960336Z"
    }
   },
   "source": [
    "### Random Forest\n",
    "# base_model = RandomForestClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "# model = MultiOutputClassifierCustom(base_model)\n",
    "# model.fit(X_train_race, y_train_race)\n",
    "###\n",
    "\n",
    "### LightGBM\n",
    "# base_model = LGBMClassifier(\n",
    "#     n_estimators=5000,\n",
    "#     random_state=42,\n",
    "#     enable_categorical=True,\n",
    "#     early_stopping_rounds=100,\n",
    "#     verbose=-1,\n",
    "# )\n",
    "# model = MultiOutputClassifierCustom(base_model)\n",
    "# model.fit(\n",
    "#     X_train_race, y_train_race,\n",
    "#     eval_set=[(X_val_race, y_val_race)],\n",
    "#     categorical_feature=cat_feature_indices,\n",
    "# )\n",
    "###\n",
    "\n",
    "### XGBoost\n",
    "### LGBM은 categorical_feature로 범주형 변수를 지정할 수 있는데 XGBoost는 내부적으로 category타입인 것을 자동으로 처리하는듯\n",
    "# col_names = [f\"{col}_p{p}\"\n",
    "#              for p in range(per_race)\n",
    "#              for col in X_train.columns]\n",
    "# X_df = pd.DataFrame(X_train_race, columns=col_names)\n",
    "#\n",
    "# cat_cols_df = [X_df.columns[i] for i in cat_feature_indices]\n",
    "# for col in cat_cols_df:\n",
    "#     X_df[col] = X_df[col].astype('category')\n",
    "#\n",
    "# base_model = XGBClassifier(\n",
    "#     n_estimators=5000,\n",
    "#     random_state=42,\n",
    "#     enable_categorical=True,\n",
    "#     early_stopping_rounds=100,\n",
    "#\n",
    "# )\n",
    "# model = MultiOutputClassifierCustom(base_model)\n",
    "# model.fit(\n",
    "#     X_df, y_train_race,\n",
    "#     eval_set=[(X_val_race, y_val_race)],\n",
    "#     verbose=0,\n",
    "# )\n",
    "###\n",
    "\n",
    "### Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_race = scaler.fit_transform(X_train_race)\n",
    "X_val_race = scaler.transform(X_val_race)\n",
    "X_test_race = scaler.transform(X_test_race)\n",
    "\n",
    "base_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    max_iter=1000,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "model = MultiOutputClassifierCustom(base_model)\n",
    "model.fit(X_train_race, y_train_race)\n",
    "###"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifierCustom(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                         n_jobs=-1,\n",
       "                                                         random_state=42))"
      ],
      "text/html": [
       "<style>#sk-container-id-19 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-19 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-19 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-19 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-19 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-19 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-19 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-19 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-19 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-19 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-19 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputClassifierCustom(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                         n_jobs=-1,\n",
       "                                                         random_state=42))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultiOutputClassifierCustom</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultiOutputClassifierCustom(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                         n_jobs=-1,\n",
       "                                                         random_state=42))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: LogisticRegression</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "id": "574688f9-2bc9-44f5-b91d-4b51235b2ebb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:17:26.460667Z",
     "start_time": "2025-04-25T13:17:26.203627Z"
    }
   },
   "source": [
    "y_train_pred_race = model.predict_proba(X_train_race)\n",
    "y_val_pred_race = model.predict_proba(X_val_race)\n",
    "y_test_pred_race = model.predict_proba(X_test_race)\n",
    "\n",
    "print(y_train_pred_race.shape, y_val_pred_race.shape, y_test_pred_race.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25248, 7) (1578, 7) (1578, 7)\n"
     ]
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:17:27.754922Z",
     "start_time": "2025-04-25T13:17:27.624921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 단승: top_k=1, 복승:top_k=2, 삼복승:top_k=3\n",
    "train_metrics = compute_race_metrics(y_train_race, y_train_pred_race, threshold=0.5, top_k=top_k)\n",
    "val_metrics   = compute_race_metrics(y_val_race,   y_val_pred_race,   threshold=0.5, top_k=top_k)\n",
    "test_metrics  = compute_race_metrics(y_test_race,  y_test_pred_race,  threshold=0.5, top_k=top_k)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Train\": train_metrics,\n",
    "    \"Validation\": val_metrics,\n",
    "    \"Test\": test_metrics\n",
    "})\n",
    "\n",
    "metrics_df.round(3)"
   ],
   "id": "338b4c0ce44ede5c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               Train  Validation   Test\n",
       "race_accuracy  0.311        0.25  0.272"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>race_accuracy</th>\n",
       "      <td>0.311</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:17:42.316496Z",
     "start_time": "2025-04-25T13:17:42.261495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def invert_reshape_by_race(arr: np.ndarray, per_race: int = 7) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    reshape_by_race의 역함수.\n",
    "\n",
    "    - 입력 배열 arr의 shape이 (n_races, per_race)라면\n",
    "      1D 벡터 (n_races * per_race,)로 복원합니다.\n",
    "\n",
    "    - 입력 배열 arr의 shape이 (n_races, per_race * n_features)라면\n",
    "      2D 행렬 (n_races * per_race, n_features)로 복원합니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : np.ndarray, shape (n_races, M)\n",
    "        reshape_by_race의 출력 배열.\n",
    "    per_race : int, default=7\n",
    "        한 경주당 샘플 수. reshape_by_race와 동일한 값을 써야 합니다.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        원래 배열 형태로 복원한 결과:\n",
    "        - 원본이 1D였으면 1D,\n",
    "        - 원본이 2D였으면 2D.\n",
    "    \"\"\"\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 2:\n",
    "        raise ValueError(f\"입력 배열은 2D여야 합니다. (현재 ndim={arr.ndim})\")\n",
    "\n",
    "    n_races, M = arr.shape\n",
    "\n",
    "    # 1D 원본 복원 (열 수가 per_race와 같을 때)\n",
    "    if M == per_race:\n",
    "        return arr.reshape(-1)\n",
    "\n",
    "    # 2D 원본 복원\n",
    "    if M % per_race != 0:\n",
    "        raise ValueError(f\"열 수({M})가 per_race({per_race})의 배수가 아닙니다.\")\n",
    "\n",
    "    n_features = M // per_race\n",
    "    return arr.reshape(n_races * per_race, n_features)\n",
    "\n",
    "\n",
    "y_train_pred = invert_reshape_by_race(y_train_pred_race, per_race=7)\n",
    "y_val_pred = invert_reshape_by_race(y_val_pred_race, per_race=7)\n",
    "y_test_pred = invert_reshape_by_race(y_test_pred_race, per_race=7)\n",
    "\n",
    "print(y_train_pred.shape, y_val_pred.shape, y_test_pred.shape)"
   ],
   "id": "e7e5fd1e8a3ce374",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176736,) (11046,) (11046,)\n"
     ]
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T13:17:43.177268Z",
     "start_time": "2025-04-25T13:17:42.578986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train set metrics\n",
    "train_accuracy = accuracy_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Validation set metrics\n",
    "val_accuracy = accuracy_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Test set metrics\n",
    "test_accuracy = accuracy_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Train': [train_accuracy, train_auc, train_f1, train_r2],\n",
    "    'Validation': [val_accuracy, val_auc, val_f1, val_r2],\n",
    "    'Test': [test_accuracy, test_auc, test_f1, test_r2]\n",
    "}, index=['Accuracy', 'AUC', 'F1', 'R2'])\n",
    "\n",
    "metrics_df.round(3)"
   ],
   "id": "9ea0fcfe9e22ee94",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          Train  Validation   Test\n",
       "Accuracy  0.767       0.739  0.749\n",
       "AUC       0.836       0.809  0.818\n",
       "F1        0.708       0.686  0.700\n",
       "R2        0.342       0.251  0.273"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.767</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.836</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.708</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.342</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 229
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "470f5a6a17b5c94f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
