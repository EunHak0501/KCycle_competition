{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 데이터 로드",
   "id": "693d76f4ad5e4cdc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:27:02.211115Z",
     "start_time": "2025-04-23T17:27:00.023275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from kcycle.loader import load_data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, r2_score, hamming_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "train = load_data()\n",
    "sample = pd.read_csv('./data/20250420_광명01경주_sample.csv')\n",
    "\n",
    "print(train.shape, sample.shape)"
   ],
   "id": "2414392294b9ab7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137207, 45) (7, 44)\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:23.294796Z",
     "start_time": "2025-04-23T16:43:19.048387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_race_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # 드롭할 컬럼\n",
    "    drop_cols = [\n",
    "        # '날짜',\n",
    "        '경주시간', '이름', '기수', '훈련지',\n",
    "        '훈련동참자', '훈련내용', '훈련일수',\n",
    "        '최근3_장소일자', '최근2_장소일자', '최근1_장소일자'\n",
    "    ]\n",
    "    df = df.drop(columns=drop_cols, errors='ignore')\n",
    "\n",
    "    # 광명에서 경주한 것만 필터링\n",
    "    df = df[df['경주지역'] == '광명'].reset_index(drop=True)\n",
    "\n",
    "    # 기어배수 처리\n",
    "    df['기어배수'] = df['기어배수'].astype(str).str.strip().str[:4]\n",
    "\n",
    "    # 200m 처리\n",
    "    df['200m'] = df['200m'].astype(str).str.replace('\"', '.', regex=False)\n",
    "\n",
    "    # 지표관련 변수 처리\n",
    "    cols = ['승률', '연대율', '삼연대율', '입상/출전', '선행', '젖히기', '추입', '마크']\n",
    "    for col in cols:\n",
    "        col_str = df[col].astype(str)\n",
    "\n",
    "        # 괄호 안쪽 데이터 사용\n",
    "        # inner = col_str.str.extract(r\"\\((.*?)\\)\")[0]\n",
    "        # df[col] = col_str.str.extract(r\"\\((.*?)\\)\")[0]\n",
    "        # df[col] = inner.fillna(col_str)\n",
    "\n",
    "        # 괄호 바깥쪽 데이터 사용\n",
    "        df[col] = col_str.str.replace(r\"\\(.*?\\)\", \"\", regex=True).str.strip()\n",
    "\n",
    "    # '/'가 포함되어있는 변수 처리\n",
    "    # '입상/출전' 분리\n",
    "    ratio_split = df['입상/출전'].astype(str).str.extract(r\"(\\d+)/(\\d+)\")\n",
    "    df['입상'] = pd.to_numeric(ratio_split[0], errors='coerce')\n",
    "    df['출전'] = pd.to_numeric(ratio_split[1], errors='coerce')\n",
    "    df = df.drop(columns='입상/출전')\n",
    "\n",
    "    # '최근3순위' 계산 (소수) ('279/554' → 0.5036)\n",
    "    ratio_recent = df['최근3순위'].astype(str).str.extract(r\"(\\d+)/(\\d+)\")\n",
    "    a = pd.to_numeric(ratio_recent[0], errors='coerce')\n",
    "    b = pd.to_numeric(ratio_recent[1], errors='coerce')\n",
    "    df['최근3순위'] = a / b\n",
    "\n",
    "    # 등급조정, 현재와 이전 등급 분리\n",
    "    s = df['등급조정'].astype(str)\n",
    "    df['현재_등급'] = s.str.slice(5, 7)\n",
    "    df['이전_등급'] = s.str.slice(12, 14)\n",
    "    df = df.drop(columns='등급조정')\n",
    "\n",
    "    # 최근3득점: 광명과 종합 점수 분리\n",
    "    s = df['최근3득점'].astype(str)\n",
    "    gwang = s.str.extract(r\"\\(광명\\)\\s*([\\d.]+)\")[0]\n",
    "    jonghap = s.str.extract(r\"\\(종합\\)\\s*([\\d.]+)\")[0]\n",
    "    df['광명_3득점'] = pd.to_numeric(gwang, errors='coerce')\n",
    "    df['종합_3득점'] = pd.to_numeric(jonghap, errors='coerce')\n",
    "    df = df.drop(columns='최근3득점')\n",
    "\n",
    "    cols = [\n",
    "        '최근3_1일', '최근3_2일', '최근3_3일',\n",
    "        '최근2_1일', '최근2_2일', '최근2_3일',\n",
    "        '최근1_1일', '최근1_2일', '최근1_3일',\n",
    "        '금회_1일', '금회_2일', '금회_3일',\n",
    "    ]\n",
    "    for col in cols:\n",
    "        col_data = df[col].astype(str)\n",
    "        pattern = r'^(\\S{2})\\s*(\\d+)-(\\d+)(\\S?)'\n",
    "\n",
    "        extracted = col_data.str.extract(pattern)\n",
    "        # df[f'{col}_종류'] = extracted[0]\n",
    "        df[f'{col}_순위'] = pd.to_numeric(extracted[2], errors='coerce').clip(upper=7)\n",
    "        # df[f'{col}_전법'] = extracted[3]\n",
    "        df = df.drop(columns=col)\n",
    "\n",
    "    # 경주종류 단순화\n",
    "    mapping = {\n",
    "        '특선': '특선',\n",
    "        '특별특선': '특선',\n",
    "        '특선결승': '특선결승',\n",
    "        '특선준결': '특선결승',\n",
    "        '그랑프리결승': '특선결승',\n",
    "        '우수': '우수',\n",
    "        '우수결승': '우수결승',\n",
    "        '우수준결': '우수결승',\n",
    "        '선발': '선발',\n",
    "        '선발결승': '선발결승',\n",
    "        '선발준결': '선발결승',\n",
    "\n",
    "        '준결': '특선', # 준결 경기에는 S등급 선수들이 가장 많음\n",
    "        '특별': '우수', # 특별 경기에는 A등급 선수들이 가장 많음\n",
    "        '특우': '특선', # 특우 경기에는 S등급 선수들이 가장 많음\n",
    "        '특별우수': '우수',\n",
    "    }\n",
    "    df['경주종류'] = df['경주종류'].map(mapping)\n",
    "\n",
    "    return df\n",
    "\n",
    "train = clean_race_data(train)\n",
    "sample = clean_race_data(sample)"
   ],
   "id": "47dc2432591bb58e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train, Valid, Test split",
   "id": "7c9c8e024babfd26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:23.549742Z",
     "start_time": "2025-04-23T16:43:23.325743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def split_train_test_by_race(df, test_size=0.2) -> (pd.DataFrame, pd.DataFrame):\n",
    "    # '경주' 단위로 train/test 분리 (한 경주에 속한 모든 선수는 같은 세트에 속하도록).\n",
    "    # 미래의 경주 데이터로 과거의 경주를 예측하지 않도록 shuffle은 X.\n",
    "\n",
    "    df = df.copy()\n",
    "    df['race_id'] = (\n",
    "        df['연도'].astype(str) + '_' +\n",
    "        df['회차'].astype(str) + '_' +\n",
    "        df['일차'].astype(str) + '_' +\n",
    "        df['경주번호']\n",
    "    )\n",
    "\n",
    "    unique_races = df['race_id'].drop_duplicates().tolist()\n",
    "    n = len(unique_races)\n",
    "    cutoff = int(n * (1 - test_size))\n",
    "\n",
    "    train_race_ids = set(unique_races[:cutoff])\n",
    "    test_race_ids  = set(unique_races[cutoff:])\n",
    "\n",
    "    train_df = df[df['race_id'].isin(train_race_ids)].drop(columns='race_id').reset_index(drop=True)\n",
    "    test_df  = df[df['race_id'].isin(test_race_ids )].drop(columns='race_id').reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "train, val = split_train_test_by_race(train, test_size=0.2)\n",
    "val, test = split_train_test_by_race(val, test_size=0.5)"
   ],
   "id": "ec65324def7aac40",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data Preprocessing",
   "id": "36198f85cac5e24e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:25.022886Z",
     "start_time": "2025-04-23T16:43:23.580902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def impute_missing_value(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    # 선수가 속한 현재 등급의 평균으로 대체\n",
    "    train['200m'] = pd.to_numeric(train['200m'].replace('-', pd.NA), errors='coerce')\n",
    "    valid['200m'] = pd.to_numeric(valid['200m'].replace('-', pd.NA), errors='coerce')\n",
    "\n",
    "    group_means = train.groupby('현재_등급')['200m'].mean()\n",
    "    train['200m'] = train.apply(\n",
    "        lambda row: group_means[row['현재_등급']] if pd.isna(row['200m']) else row['200m'],\n",
    "        axis=1\n",
    "    )\n",
    "    valid['200m'] = valid.apply(\n",
    "        lambda row: group_means.get(row['현재_등급'], pd.NA) if pd.isna(row['200m']) else row['200m'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    group_means = train.groupby('현재_등급')['종합_3득점'].mean()\n",
    "    train['종합_3득점'] = train.apply(\n",
    "        lambda row: group_means[row['현재_등급']] if pd.isna(row['종합_3득점']) else row['종합_3득점'],\n",
    "        axis=1\n",
    "    )\n",
    "    valid['종합_3득점'] = valid.apply(\n",
    "        lambda row: group_means.get(row['현재_등급'], pd.NA) if pd.isna(row['종합_3득점']) else row['종합_3득점'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # 최근 순위가 결측인 경우(후보, 결장 등), 입상하지 못한 것과 동일하게 대체\n",
    "    # 순위보다 입상여부, 입상을 했으면 몇등을 했는지가 중요하다고 판단\n",
    "    # 1,2,3 > 순위 / 4 > 미입상\n",
    "    cols = [\n",
    "        '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "        '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "        '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "        '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "    ]\n",
    "    train[cols] = train[cols].fillna(7).clip(upper=4)\n",
    "    valid[cols] = valid[cols].fillna(7).clip(upper=4)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def drop_constant_columns(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    nunique = train.nunique()\n",
    "    constant_cols = nunique[nunique == 1].index.tolist()\n",
    "\n",
    "    train = train.drop(columns=constant_cols)\n",
    "    valid = valid.drop(columns=constant_cols)\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def drop_unused_columns(df):\n",
    "    cols_to_drop = [\n",
    "        '날짜', '연도', '회차', '일차', '경주번호',\n",
    "    ]\n",
    "\n",
    "    return df.drop(columns=cols_to_drop)\n",
    "\n",
    "def encode_categorical(train: pd.DataFrame, valid: pd.DataFrame):\n",
    "    cat_cols = [\n",
    "        '경주종류', '번호', '현재_등급', '이전_등급',\n",
    "        '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "        '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "        '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "        '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "    ]\n",
    "\n",
    "    for col in cat_cols:\n",
    "        encoder = LabelEncoder()\n",
    "        train[col] = encoder.fit_transform(train[col])\n",
    "        valid[col] = encoder.transform(valid[col])\n",
    "\n",
    "    return train, valid\n",
    "\n",
    "def cast_features(df):\n",
    "    cols = [col for col in df.columns]\n",
    "    df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "def all_process(train, valid):\n",
    "    train, valid = impute_missing_value(train, valid)\n",
    "    train, valid = drop_constant_columns(train, valid)\n",
    "    train, valid = drop_unused_columns(train), drop_unused_columns(valid)\n",
    "    train, valid = encode_categorical(train, valid)\n",
    "    train, valid = cast_features(train), cast_features(valid)\n",
    "    return train, valid\n",
    "\n",
    "train, val = all_process(train, val)"
   ],
   "id": "4811c82ad364ab79",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:25.082979Z",
     "start_time": "2025-04-23T16:43:25.069970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_target(df, bet_type='복승'):\n",
    "    \"\"\"\n",
    "    bet_type:\n",
    "      - '삼복승': rank <= 3  →  target=1\n",
    "      - '복승':   rank <= 2  → target=1\n",
    "      - '단승':   rank == 1  → target=1\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    # 기준 등수 설정\n",
    "    if bet_type == '삼복승':\n",
    "        cutoff = 3\n",
    "        df['target'] = (df['rank'] <= cutoff).astype(int)\n",
    "    elif bet_type == '복승':\n",
    "        cutoff = 2\n",
    "        df['target'] = (df['rank'] <= cutoff).astype(int)\n",
    "    elif bet_type == '단승':\n",
    "        # ==1 일 때만 1\n",
    "        df['target'] = (df['rank'] == 1).astype(int)\n",
    "    else:\n",
    "        raise ValueError(f\"알 수 없는 bet_type: {bet_type!r}. ('단승','복승','삼복승' 중 하나)\")\n",
    "\n",
    "    df = df.drop(columns=['rank'])\n",
    "\n",
    "    return df"
   ],
   "id": "bca9053e73565b39",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:34.207989Z",
     "start_time": "2025-04-23T16:43:25.115004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = load_data()\n",
    "train = clean_race_data(train)\n",
    "train, val = split_train_test_by_race(train, test_size=0.2)\n",
    "val, test = split_train_test_by_race(val, test_size=0.5)\n",
    "train_ = train.copy()\n",
    "\n",
    "train, val = all_process(train, val)\n",
    "_, test = all_process(train_, test)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ],
   "id": "8baa28f9a4bba313",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n",
      "C:\\Users\\eunhak\\AppData\\Local\\Temp\\ipykernel_7944\\1479108503.py:74: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df[cols] = df[cols].apply(pd.to_numeric, errors='ignore')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88368, 32) (11046, 32) (11046, 32)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:34.282989Z",
     "start_time": "2025-04-23T16:43:34.253990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = add_target(train, bet_type='복승')\n",
    "val = add_target(val, bet_type='복승')\n",
    "test = add_target(test, bet_type='복승')"
   ],
   "id": "c3baf4a95c124b32",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Model Training",
   "id": "a338962538e0755c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:44:34.048725Z",
     "start_time": "2025-04-23T16:44:33.645728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = train.drop(columns=['target'])\n",
    "X_val = val.drop(columns=['target'])\n",
    "X_test = test.drop(columns=['target'])\n",
    "\n",
    "y_train = train['target']\n",
    "y_val = val['target']\n",
    "y_test = test['target']\n",
    "\n",
    "cat_cols = [\n",
    "    '경주종류', '번호', '현재_등급', '이전_등급',\n",
    "    '최근3_1일_순위', '최근3_2일_순위', '최근3_3일_순위',\n",
    "    '최근2_1일_순위', '최근2_2일_순위', '최근2_3일_순위',\n",
    "    '최근1_1일_순위', '최근1_2일_순위', '최근1_3일_순위',\n",
    "    '금회_1일_순위', '금회_2일_순위', '금회_3일_순위'\n",
    "]\n",
    "X_train[cat_cols] = X_train[cat_cols].astype('category')\n",
    "X_val[cat_cols] = X_val[cat_cols].astype('category')\n",
    "X_test[cat_cols] = X_test[cat_cols].astype('category')\n",
    "\n",
    "\n",
    "# model = LGBMClassifier(\n",
    "#     n_estimators=5000,\n",
    "#     random_state=42,\n",
    "#     enable_categorical=True,\n",
    "#     early_stopping_rounds=100,\n",
    "#     verbose=-1,\n",
    "# )\n",
    "# model.fit(\n",
    "#     X_train, y_train,\n",
    "#     eval_set=(X_val, y_val),\n",
    "#     categorical_feature=cat_cols\n",
    "# )\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=5000,\n",
    "    random_state=42,\n",
    "    enable_categorical=True,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=1000,\n",
    "#     random_state=42,\n",
    "#     n_jobs=-1,\n",
    "# )\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = model.predict_proba(X_train)[:, 1]\n",
    "y_val_pred = model.predict_proba(X_val)[:, 1]\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]"
   ],
   "id": "79a92d799c79224d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluation",
   "id": "ebf53d04e989976a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 개별 지표",
   "id": "184a37cfbf13db69"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:03:55.777917Z",
     "start_time": "2025-04-23T17:03:55.723917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train set metrics\n",
    "train_accuracy = accuracy_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_auc = roc_auc_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, (y_train_pred > 0.5).astype(int))\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Validation set metrics \n",
    "val_accuracy = accuracy_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_auc = roc_auc_score(y_val, y_val_pred)\n",
    "val_f1 = f1_score(y_val, (y_val_pred > 0.5).astype(int))\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Test set metrics\n",
    "test_accuracy = accuracy_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, (y_test_pred > 0.5).astype(int))\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Train': [train_accuracy, train_auc, train_f1, train_r2],\n",
    "    'Validation': [val_accuracy, val_auc, val_f1, val_r2],\n",
    "    'Test': [test_accuracy, test_auc, test_f1, test_r2]\n",
    "}, index=['Accuracy', 'AUC', 'F1', 'R2'])\n",
    "\n",
    "metrics_df.round(4)"
   ],
   "id": "bef31e179295708",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           Train  Validation    Test\n",
       "Accuracy  0.8104      0.7835  0.7799\n",
       "AUC       0.8452      0.8142  0.8153\n",
       "F1        0.6125      0.5799  0.5632\n",
       "R2        0.3335      0.2557  0.2620"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.8104</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.8452</td>\n",
       "      <td>0.8142</td>\n",
       "      <td>0.8153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.6125</td>\n",
       "      <td>0.5799</td>\n",
       "      <td>0.5632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R2</th>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.2620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "- 경주별 지표",
   "id": "7e6c37eb75846287"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:25:26.545243Z",
     "start_time": "2025-04-23T17:25:26.534243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def reshape_by_race(arr: np.ndarray, per_race: int = 7) -> np.ndarray:\n",
    "    # 1차원 배열을 경주 단위로 묶어 2차원 배열로 변환\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim != 1:\n",
    "        raise ValueError(f\"입력 배열은 1차원이어야 합니다. (현재 ndim={arr.ndim})\")\n",
    "    total = arr.size\n",
    "    if total % per_race != 0:\n",
    "        raise ValueError(f\"배열 길이({total})가 per_race({per_race})의 배수가 아닙니다.\")\n",
    "    return arr.reshape(-1, per_race)\n",
    "\n",
    "# y_test 배열을 (N,)에서 (N/7, 7)로 변환\n",
    "y_train_race = reshape_by_race(y_train, per_race=7)\n",
    "y_train_pred_race = reshape_by_race(y_train_pred, per_race=7)\n",
    "\n",
    "y_val_race = reshape_by_race(y_val, per_race=7)\n",
    "y_val_pred_race = reshape_by_race(y_val_pred, per_race=7)\n",
    "\n",
    "y_test_race = reshape_by_race(y_test, per_race=7)\n",
    "y_test_pred_race = reshape_by_race(y_test_pred, per_race=7)\n",
    "\n",
    "print(y_train_race.shape, y_train_pred_race.shape)\n",
    "print(y_val_race.shape, y_val_pred_race.shape)\n",
    "print(y_test_race.shape, y_test_pred_race.shape)"
   ],
   "id": "1712ca4a1f488ac4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12624, 7) (12624, 7)\n",
      "(1578, 7) (1578, 7)\n",
      "(1578, 7) (1578, 7)\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T17:27:39.341893Z",
     "start_time": "2025-04-23T17:27:39.305890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_race_metrics(y_true: np.ndarray,\n",
    "                         y_score: np.ndarray,\n",
    "                         threshold: float = 0.5,\n",
    "                         per_race: int = 7) -> pd.Series:\n",
    "    \"\"\"\n",
    "    경주별(7명 단위)로 묶어서 multi‐label 지표를 계산합니다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape (n_samples,)\n",
    "        실제 binary 타겟 벡터 (0/1). 길이는 per_race의 배수여야 합니다.\n",
    "    y_score : array-like, shape (n_samples,)\n",
    "        예측 확률(또는 연속 점수) 벡터.\n",
    "    threshold : float, default=0.5\n",
    "        y_score > threshold 를 positive로 간주합니다.\n",
    "    per_race : int, default=7\n",
    "        한 경주당 참가자 수.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        hamming_loss, precision_samples, recall_samples, f1_samples,\n",
    "        race_accuracy (race 단위로 모두 정확하게 맞춘 비율)\n",
    "    \"\"\"\n",
    "    # reshape to (n_races, per_race)\n",
    "    y_true_r = reshape_by_race(y_true, per_race)\n",
    "    y_score_r = reshape_by_race(y_score, per_race)\n",
    "    # 이진 예측\n",
    "    y_pred_r = (y_score_r > threshold).astype(int)\n",
    "\n",
    "    # multi‐label 샘플 단위 지표\n",
    "    ham = hamming_loss(y_true_r, y_pred_r)\n",
    "    f1 = f1_score(y_true_r, y_pred_r, average=\"samples\", zero_division=0)\n",
    "\n",
    "    # race‐level accuracy: 한 경주의 7명 모두를 정확히 맞춘 비율\n",
    "    correct_per_race = np.all(y_true_r == y_pred_r, axis=1)\n",
    "    race_acc = correct_per_race.mean()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"hamming_loss\": ham,\n",
    "        \"f1_samples\": f1,\n",
    "        \"race_accuracy\": race_acc\n",
    "    })\n",
    "\n",
    "# 예시 사용\n",
    "# y_train, y_train_pred 준비되어 있다고 가정\n",
    "train_metrics = compute_race_metrics(y_train, y_train_pred, threshold=0.5, per_race=7)\n",
    "val_metrics   = compute_race_metrics(y_val,   y_val_pred,   threshold=0.5, per_race=7)\n",
    "test_metrics  = compute_race_metrics(y_test,  y_test_pred,  threshold=0.5, per_race=7)\n",
    "\n",
    "metrics_df = pd.DataFrame({\n",
    "    \"Train\": train_metrics,\n",
    "    \"Validation\": val_metrics,\n",
    "    \"Test\": test_metrics\n",
    "})\n",
    "\n",
    "metrics_df.round(4)"
   ],
   "id": "3d2edcfcd92f8b29",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                Train  Validation    Test\n",
       "hamming_loss   0.1896      0.2165  0.2201\n",
       "f1_samples     0.5571      0.5388  0.5226\n",
       "race_accuracy  0.1957      0.1305  0.1109"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hamming_loss</th>\n",
       "      <td>0.1896</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_samples</th>\n",
       "      <td>0.5571</td>\n",
       "      <td>0.5388</td>\n",
       "      <td>0.5226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_accuracy</th>\n",
       "      <td>0.1957</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>0.1109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# # 특정 라인을 제외하고 섞기(선택 가능)\n",
    "# def shuffle_races(data, year, ratio, exclude_back_no_list=None, random_seed=None):\n",
    "#\n",
    "#     if random_seed is not None:\n",
    "#         np.random.seed(random_seed)\n",
    "#\n",
    "#     df_year = data[data['BASE_YEAR'] == year].copy()\n",
    "#\n",
    "#     # 각 경기를 구분하는 고유한 식별자 생성\n",
    "#     df_year['RACE_ID'] = df_year.groupby(['TME_VALUE', 'DAY_ORD_VALUE', 'RACE_NO']).ngroup()\n",
    "#\n",
    "#     # 경기 ID의 리스트 생성\n",
    "#     race_ids = df_year['RACE_ID'].unique()\n",
    "#\n",
    "#     # 경기 ID 리스트에서 주어진 비율만큼 무작위 추출 (random_state 추가)\n",
    "#     selected_race_ids = np.random.choice(race_ids, int(len(race_ids) * ratio), replace=False)\n",
    "#\n",
    "#     # 추출된 경기만 포함하는 데이터 프레임 생성\n",
    "#     df_sampled = df_year[df_year['RACE_ID'].isin(selected_race_ids)]\n",
    "#\n",
    "#     grouped = df_sampled.groupby(['TME_VALUE', 'DAY_ORD_VALUE', 'RACE_NO'])\n",
    "#\n",
    "#     shuffled_dfs = []\n",
    "#\n",
    "#     for name, group in grouped:\n",
    "#         if exclude_back_no_list:\n",
    "#             rows_exclude_list = []\n",
    "#             for exclude_back_no in exclude_back_no_list:\n",
    "#                 row_exclude = group[group['BACK_NO'] == exclude_back_no]\n",
    "#                 rows_exclude_list.append(row_exclude)\n",
    "#\n",
    "#             # 샘플링 시 random_state 추가\n",
    "#             shuffled_rows_except_excluded = group[~group['BACK_NO'].isin(exclude_back_no_list)].sample(frac=1.0, random_state=random_seed)\n",
    "#\n",
    "#             first_half_shuffled_rows_except_excluded = shuffled_rows_except_excluded[shuffled_rows_except_excluded.index < rows_exclude_list[0].index[0]]\n",
    "#             second_half_shuffled_rows_except_excluded = shuffled_rows_except_excluded[shuffled_rows_except_excluded.index > rows_exclude_list[-1].index[0]]\n",
    "#\n",
    "#             shuffled_group = pd.concat([first_half_shuffled_rows_except_excluded] + rows_exclude_list + [second_half_shuffled_rows_except_excluded])\n",
    "#         else:\n",
    "#             # 샘플링 시 random_state 추가\n",
    "#             shuffled_group = group.sample(frac=1.0, random_state=random_seed)\n",
    "#\n",
    "#        # 결과 리스트에 추가합니다.\n",
    "#         shuffled_dfs.append(shuffled_group)\n",
    "#\n",
    "#     # 모든 셔플된 그룹을 합칩니다.\n",
    "#     df_shuffled = pd.concat(shuffled_dfs)\n",
    "#     df_shuffled = df_shuffled.reset_index(drop=True)\n",
    "#     df_shuffled.drop(['RACE_ID'], axis=1, inplace=True)\n",
    "#\n",
    "#     return df_shuffled\n",
    "#\n",
    "#\n",
    "# # 순서를 완전히 반대로\n",
    "# def reverse_order(data, year, ratio, random_seed=None):\n",
    "#     if random_seed is not None:\n",
    "#         np.random.seed(random_seed)\n",
    "#\n",
    "#     df_year = data[data['BASE_YEAR'] == year].copy()\n",
    "#\n",
    "#     # 각 경기를 구분하는 고유한 식별자 생성\n",
    "#     df_year['RACE_ID'] = df_year.groupby(['TME_VALUE', 'DAY_ORD_VALUE', 'RACE_NO']).ngroup()\n",
    "#\n",
    "#     # 경기 ID의 리스트 생성\n",
    "#     race_ids = df_year['RACE_ID'].unique()\n",
    "#\n",
    "#     # 경기 ID 리스트에서 주어진 비율만큼 무작위 추출\n",
    "#     selected_race_ids = np.random.choice(race_ids, int(len(race_ids) * ratio), replace=False)\n",
    "#\n",
    "#     # 추출된 경기만 포함하는 데이터 프레임 생성\n",
    "#     df_sampled = df_year[df_year['RACE_ID'].isin(selected_race_ids)]\n",
    "#\n",
    "#      # 그룹 생성\n",
    "#     grouped = df_sampled.groupby(['TME_VALUE', 'DAY_ORD_VALUE', 'RACE_NO'])\n",
    "#\n",
    "#     reversed_dfs = []\n",
    "#\n",
    "#     for name, group in grouped:\n",
    "#          # 각 그룹의 행 순서를 반대로 하고 결과 리스트에 추가합니다.\n",
    "#         reversed_group  = group.iloc[::-1]\n",
    "#         reversed_dfs.append(reversed_group)\n",
    "#\n",
    "#      # 모든 뒤집힌 그룹을 합칩니다.\n",
    "#     df_reversed= pd.concat(reversed_dfs)\n",
    "#     df_reversed.drop(['RACE_ID'], axis=1,inplace=True)\n",
    "#\n",
    "#     return df_reversed.reset_index(drop=True)\n"
   ],
   "id": "379eb1bebb7dae69"
  },
  {
   "cell_type": "code",
   "id": "d5012a6b-73d7-4102-84f8-d98ab70c0e4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-23T16:43:34.702772300Z",
     "start_time": "2025-04-23T16:09:03.409569Z"
    }
   },
   "source": [
    "# years = range(2016, 2024)\n",
    "#\n",
    "# df_shuffled1 = {}\n",
    "# df_shuffled2 = {}\n",
    "# df_shuffled3 = {}\n",
    "#\n",
    "# print('4번을 제외하고 섞기')\n",
    "# for year in years:\n",
    "#     ratio = 1.0 if year >= 2021 else 0.5\n",
    "#     df_shuffled1[year] = shuffle_races(data=train_data,\n",
    "#                                       year=year,\n",
    "#                                       ratio=ratio,\n",
    "#                                       exclude_back_no_list=[4],\n",
    "#                                       random_seed=42)\n",
    "#     print(year, df_shuffled1[year].shape)\n",
    "#\n",
    "# print('-'*15)\n",
    "# print('\\n무작위로 섞기')\n",
    "#\n",
    "# for year in years:\n",
    "#     ratio = 0.4 if year >= 2021 else 0.2\n",
    "#     df_shuffled2[year] = shuffle_races(data=train_data,\n",
    "#                                       year=year,\n",
    "#                                       ratio=ratio,\n",
    "#                                       exclude_back_no_list=None,\n",
    "#                                       random_seed=42)\n",
    "#     print(year, df_shuffled2[year].shape)\n",
    "#\n",
    "# print('-'*15)\n",
    "# print('\\n순서를 뒤집기')\n",
    "#\n",
    "# for year in years:\n",
    "#     ratio = 1.0 if year >= 2021 else 0.5\n",
    "#     df_shuffled3[year] = reverse_order(data=train_data,\n",
    "#                                       year=year,\n",
    "#                                       ratio=ratio,\n",
    "#                                       random_seed=42)\n",
    "#     print(year, df_shuffled3[year].shape)"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "59654f2389b4992d"
  },
  {
   "cell_type": "code",
   "id": "bf1dd7a8-5bc2-4f85-bcfd-69b175b0cb97",
   "metadata": {},
   "source": [
    "# reshape 기능을 이용해 7명의 선수를 하나의 데이터로 합치기 (train data)\n",
    "n_samples1 = len(input_train) // 7\n",
    "n_samples2 = len(output_train) // 7\n",
    "n_rows = 7\n",
    "n_cols1 = input_train.shape[1]\n",
    "n_cols2 = 1\n",
    "\n",
    "reshaped_input_train = input_train.values.reshape((n_samples1, n_rows, n_cols1))\n",
    "reshaped_output_train = output_train.values.reshape((n_samples2, n_rows, n_cols2))\n",
    "\n",
    "reshaped_input_train = reshaped_input_train.reshape(-1, n_rows * n_cols1) \n",
    "reshaped_output_train = reshaped_output_train.reshape(-1, n_rows * n_cols2)\n",
    "\n",
    "display(reshaped_input_train.shape, reshaped_output_train.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "92d2cfab-c670-4e33-b394-96869e53af8d",
   "metadata": {},
   "source": [
    "# reshape 기능을 이용해 7명의 선수를 하나의 데이터로 합치기 (test data)\n",
    "n_samples1 = len(input_test) // 7\n",
    "n_samples2 = len(output_test) // 7\n",
    "n_rows = 7\n",
    "n_cols1 = input_test.shape[1]\n",
    "n_cols2 = 1\n",
    "\n",
    "reshaped_input_test = input_test.values.reshape((n_samples1, n_rows, n_cols1))\n",
    "reshaped_output_test = output_test.values.reshape((n_samples2, n_rows, n_cols2))\n",
    "\n",
    "reshaped_input_test = reshaped_input_test.reshape(-1, n_rows * n_cols1) \n",
    "reshaped_output_test = reshaped_output_test.reshape(-1, n_rows * n_cols2)\n",
    "\n",
    "display(reshaped_input_test.shape, reshaped_output_test.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "469ce2b1-826c-40c6-a061-e2584272d048",
   "metadata": {},
   "source": [
    "# reshape 기능을 이용해 7명의 선수를 하나의 데이터로 합치기 (test data)\n",
    "n_samples1 = len(input_sample) // 7\n",
    "n_rows = 7\n",
    "n_cols1 = input_sample.shape[1]\n",
    "\n",
    "reshaped_input_sample = input_sample.values.reshape((n_samples1, n_rows, n_cols1))\n",
    "\n",
    "reshaped_input_sample = reshaped_input_sample.reshape(-1, n_rows * n_cols1) \n",
    "\n",
    "display(reshaped_input_sample.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c1f8b288-546c-45a2-90df-5c4a73898fea",
   "metadata": {},
   "source": [
    "import time\n",
    "import optuna\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "def objective(trial):\n",
    "    # classifier_name = trial.suggest_categorical('classifier', ['DecisionTree', 'LGBM', 'XGBoost', 'CatBoost'])\n",
    "    global iteration\n",
    "    start_time = time.time()\n",
    "    \n",
    "    classifier_name = 'XGBoost'\n",
    "       \n",
    "    if classifier_name == 'LGBM':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 200, 700),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.02, 0.3, log=True),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 15, 128),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 30),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0.0, 0.5),\n",
    "            'boosting_type': trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0.0, 0.5),  # L2 정규화\n",
    "            'num_threads': 2,\n",
    "#            'device': 'gpu',\n",
    "            \n",
    "        }\n",
    "        model_lgbm = LGBMClassifier(**param, verbose=0)\n",
    "        model = MultiOutputClassifier(model_lgbm, n_jobs=4)\n",
    "        \n",
    "    elif classifier_name == 'XGBoost':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 150, 700),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 50),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.5, 1),\n",
    "            'colsample_bynode': trial.suggest_float('colsample_bynode', 0.5, 1),\n",
    "            'reg_alpha': trial.suggest_float('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_float('reg_lambda', 0, 1),\n",
    "            'scale_pos_weight': trial.suggest_float('scale_pos_weight', 1, 100),\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 10),\n",
    "            'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear']),\n",
    "            'tree_method': trial.suggest_categorical('tree_method', ['auto', 'hist']),\n",
    "            'n_jobs': 7,\n",
    "            'random_state': 42,\n",
    "        }\n",
    "        model = xgb.XGBClassifier(**param)\n",
    "    \n",
    "    elif classifier_name == 'RandomForest':\n",
    "        param = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 60),\n",
    "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "            'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n",
    "            'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "            'n_jobs': 7,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        model = RandomForestClassifier(**param)\n",
    "\n",
    "\n",
    "    model.fit(reshaped_input_train, reshaped_output_train)   # 데이터 셋 이름에 맞게 수정\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Trial {iteration} 완료, 경과 시간: {elapsed_time:.2f}초')\n",
    "    iteration += 1\n",
    "\n",
    "    y_pred_proba = model.predict_proba(reshaped_input_test)\n",
    "#    y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "    top_3_indices = np.argsort(y_pred_proba, axis=1)[:, -3:]\n",
    "\n",
    "    # y_pred_max 초기화 (모든 값을 0으로 설정)\n",
    "    y_pred_max = np.zeros_like(y_pred_proba)\n",
    "\n",
    "    # 상위 3개 인덱스의 위치에 1 할당\n",
    "    for i, indices in enumerate(top_3_indices):\n",
    "        y_pred_max[i, indices] = 1\n",
    "\n",
    "    # perfect_match 계산\n",
    "    perfect_match = []\n",
    "    for true, pred in zip(reshaped_output_test, y_pred_max):\n",
    "        # reshaped_output_test에서 1인 값이 y_pred_max에서도 1인 값에 포함되어 있는지 확인\n",
    "        match = np.all(np.logical_or(np.logical_not(pred), true))\n",
    "        perfect_match.append(match)\n",
    "\n",
    "    perfect_match = np.array(perfect_match, dtype=int)\n",
    "\n",
    "    accuracy = np.mean(perfect_match)\n",
    "    print(\"accuracy for perfect match:\", accuracy)\n",
    "    \n",
    "    return accuracy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2511ee94-5d37-4874-8a9a-6d8bd8b14638",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "start_time = time.time()\n",
    "iteration = 0\n",
    "\n",
    "# Optuna Study 생성 및 최적화\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "# study = optuna.create_study(direction='minimize', sampler=sampler)\n",
    "study.optimize(objective, n_trials=10000)\n",
    "\n",
    "# 최적화 결과 출력\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(f'경과 시간: {elapsed_time:.2f}초')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "940c9c96-b23a-48f4-9a07-3c9690bd4554",
   "metadata": {},
   "source": [
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100,\n",
    "                               max_features='log2',\n",
    "                               max_depth=10,\n",
    "                               min_samples_split=19,\n",
    "                               min_samples_leaf=11,\n",
    "                               bootstrap=True,\n",
    "                               criterion='gini',\n",
    "                               n_jobs=-1,\n",
    "                               random_state=42,\n",
    "                              )\n",
    "\n",
    "start_time = time.time()\n",
    "model_rf = model.fit(reshaped_input_train, reshaped_output_train)\n",
    "end_time = time.time()\n",
    "\n",
    "\n",
    "# 예측\n",
    "y_pred_proba = model_rf.predict_proba(reshaped_input_test)\n",
    "y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "top_3_indices = np.argsort(y_pred_proba, axis=1)[:, -3:]\n",
    "\n",
    "# y_pred_max 초기화 (모든 값을 0으로 설정)\n",
    "y_pred_max = np.zeros_like(y_pred_proba)\n",
    "\n",
    "# 상위 3개 인덱스의 위치에 1 할당\n",
    "for i, indices in enumerate(top_3_indices):\n",
    "    y_pred_max[i, indices] = 1\n",
    "\n",
    "# perfect_match 계산\n",
    "perfect_match = []\n",
    "for true, pred in zip(reshaped_output_test, y_pred_max):\n",
    "    # reshaped_output_test에서 1인 값이 y_pred_max에서도 1인 값에 포함되어 있는지 확인\n",
    "    match = np.all(np.logical_or(np.logical_not(pred), true))\n",
    "    perfect_match.append(match)\n",
    "\n",
    "perfect_match = np.array(perfect_match, dtype=int)\n",
    "\n",
    "accuracy = np.mean(perfect_match)\n",
    "print(\"적중률 for perfect match:\", accuracy)\n",
    "print(\"Training Time: \", end_time - start_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "574688f9-2bc9-44f5-b91d-4b51235b2ebb",
   "metadata": {},
   "source": [
    "predict_value_rf = model_rf.predict_proba(reshaped_input_sample)\n",
    "predict_value_rf = np.array([proba[:, 1] for proba in predict_value_rf]).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c95d7f3-2afa-4608-a597-033c440005f0",
   "metadata": {},
   "source": [
    "pd.DataFrame(predict_value_rf, columns=[1,2,3,4,5,6,7])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c729051-c8d8-43db-91b7-b5b66de96216",
   "metadata": {},
   "source": [
    "{'n_estimators': 345, 'learning_rate': 0.08787865227073664, 'max_depth': 34, 'min_child_weight': 5, 'gamma': 1.6907684810181365, 'colsample_bytree': 0.7615149755883616, 'colsample_bylevel': 0.7440588609947394, 'colsample_bynode': 0.9843402828590834, 'reg_alpha': 0.553971009858408, 'reg_lambda': 0.581507741336692, 'scale_pos_weight': 88.18441128128285, 'max_delta_step': 5, 'booster': 'gbtree', 'tree_method': 'auto'}\n",
    "\n",
    "0.35294117647058826.\n",
    "\n",
    "\n",
    "\n",
    "{'n_estimators': 302, 'learning_rate': 0.01900359581276545, 'max_depth': 28, 'min_child_weight': 3, 'gamma': 3.321420455877387, 'colsample_bytree': 0.5977693012361819, 'colsample_bylevel': 0.560548462242929, 'colsample_bynode': 0.5936493128007223, 'reg_alpha': 0.5371370983785317, 'reg_lambda': 0.37044885052723275, 'scale_pos_weight': 45.143758969825164, 'max_delta_step': 8, 'booster': 'gbtree', 'tree_method': 'auto'}.\n",
    "\n",
    "Best is trial 133 with value: 0.36764705882352944.44"
   ]
  },
  {
   "cell_type": "code",
   "id": "29e518cb-6063-41f7-9d40-956652dfa965",
   "metadata": {},
   "source": [
    "model_xgb = xgb.XGBClassifier(random_state=42,\n",
    "                              n_estimators=100,\n",
    "                              learning_rate=0.08787865227073664,\n",
    "                              max_depth=34,\n",
    "                              min_child_weight=5,\n",
    "                              gamma=1.6907684810181365,\n",
    "                              colsample_bytree=0.7615149755883616,\n",
    "                              colsample_bylevel=0.7440588609947394,\n",
    "                              colsample_bynode=0.9843402828590834,\n",
    "                              reg_alpha=0.553971009858408,\n",
    "                              reg_lambda=0.581507741336692,\n",
    "                              scale_pos_weight=88.18441128128285,\n",
    "                              max_delta_step=5,\n",
    "                              booster='gbtree',\n",
    "                              tree_method='auto',\n",
    "                              n_jobs=-1,\n",
    "                             )\n",
    "                              \n",
    "              \n",
    "model_xgb.fit(reshaped_input_train, reshaped_output_train)\n",
    "\n",
    "\n",
    "# 예측\n",
    "y_pred_proba = model_xgb.predict_proba(reshaped_input_test)\n",
    "# y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "top_3_indices = np.argsort(y_pred_proba, axis=1)[:, -3:]\n",
    "\n",
    "# y_pred_max 초기화 (모든 값을 0으로 설정)\n",
    "y_pred_max = np.zeros_like(y_pred_proba)\n",
    "\n",
    "# 상위 3개 인덱스의 위치에 1 할당\n",
    "for i, indices in enumerate(top_3_indices):\n",
    "    y_pred_max[i, indices] = 1\n",
    "\n",
    "# perfect_match 계산\n",
    "perfect_match = []\n",
    "for true, pred in zip(reshaped_output_test, y_pred_max):\n",
    "    # reshaped_output_test에서 1인 값이 y_pred_max에서도 1인 값에 포함되어 있는지 확인\n",
    "    match = np.all(np.logical_or(np.logical_not(pred), true))\n",
    "    perfect_match.append(match)\n",
    "\n",
    "perfect_match = np.array(perfect_match, dtype=int)\n",
    "\n",
    "accuracy = np.mean(perfect_match).round(4)\n",
    "print(\"적중률: \", accuracy, '%')\n",
    "# print(\"Training Time: \", end_time - start_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dce70b70-ad3f-4640-91a9-db2ae87aaf86",
   "metadata": {},
   "source": [
    "predict_value_xg = model_xgb.predict_proba(reshaped_input_sample)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70f60c34-665d-4053-84da-9edce24f72b6",
   "metadata": {},
   "source": [
    "pd.DataFrame(predict_value_xg, columns=[1,2,3,4,5,6,7])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03d6ee34-c893-4ebc-913c-4aa7c26e99a1",
   "metadata": {},
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# 최적의 하이퍼파라미터 설정\n",
    "optimal_params = {\n",
    "    'n_estimators': 400,\n",
    "    'learning_rate': 0.052822297669108224,\n",
    "    'num_leaves': 74,\n",
    "    'max_depth': 8,\n",
    "    'reg_alpha': 0.09980125949843345,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'reg_lambda': 0.45277624619552903,\n",
    "    'num_threads': 2,\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(**optimal_params)\n",
    "model_lgbm = MultiOutputClassifier(lgbm, n_jobs=4)\n",
    "\n",
    "model_lgbm.fit(reshaped_input_train, reshaped_output_train)\n",
    "\n",
    "# 예측\n",
    "y_pred_proba = model_lgbm.predict_proba(reshaped_input_test)\n",
    "y_pred_proba = np.array([proba[:, 1] for proba in y_pred_proba]).T\n",
    "top_3_indices = np.argsort(y_pred_proba, axis=1)[:, -3:]\n",
    "\n",
    "# y_pred_max 초기화 (모든 값을 0으로 설정)\n",
    "y_pred_max = np.zeros_like(y_pred_proba)\n",
    "\n",
    "# 상위 3개 인덱스의 위치에 1 할당\n",
    "for i, indices in enumerate(top_3_indices):\n",
    "    y_pred_max[i, indices] = 1\n",
    "\n",
    "# perfect_match 계산\n",
    "perfect_match = []\n",
    "for true, pred in zip(reshaped_output_test, y_pred_max):\n",
    "    # reshaped_output_test에서 1인 값이 y_pred_max에서도 1인 값에 포함되어 있는지 확인\n",
    "    match = np.all(np.logical_or(np.logical_not(pred), true))\n",
    "    perfect_match.append(match)\n",
    "\n",
    "perfect_match = np.array(perfect_match, dtype=int)\n",
    "\n",
    "accuracy = np.mean(perfect_match)\n",
    "print(\"적중률 for perfect match:\", accuracy)\n",
    "print(\"Training Time: \", end_time - start_time)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6613bb05-fa0b-4b46-9f01-f60b42db476d",
   "metadata": {},
   "source": [
    "predict_value_lgbm = model_lgbm.predict_proba(reshaped_input_sample)\n",
    "predict_value_lgbm = np.array([proba[:, 1] for proba in predict_value_lgbm]).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85370803-8bb4-4284-aa3a-ee86eb9fe65d",
   "metadata": {},
   "source": [
    "pd.DataFrame(predict_value_lgbm, columns=[1,2,3,4,5,6,7])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "03763198-b1e5-4b18-918e-2eb578ab00c6",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# 기본 모델 정의\n",
    "base_models = [\n",
    "    MultiOutputClassifier(XGBClassifier(n_estimators=100,\n",
    "                                        learning_rate=0.08787865227073664,\n",
    "                                        max_depth=34,\n",
    "                                        min_child_weight=5,\n",
    "                                        gamma=1.6907684810181365,\n",
    "                                        colsample_bytree=0.7615149755883616,\n",
    "                                        colsample_bylevel=0.7440588609947394,\n",
    "                                        colsample_bynode=0.9843402828590834,\n",
    "                                        reg_alpha=0.553971009858408,\n",
    "                                        reg_lambda=0.581507741336692,\n",
    "                                        scale_pos_weight=88.18441128128285,\n",
    "                                        max_delta_step=5,\n",
    "                                        booster='gbtree',\n",
    "                                        tree_method='auto',\n",
    "                                        n_jobs=-1,\n",
    "                                        random_state=42)),\n",
    "    MultiOutputClassifier(LGBMClassifier(n_estimators=400,\n",
    "                                         learning_rate=0.052822297669108224,\n",
    "                                         num_leaves=74,\n",
    "                                         max_depth=8,\n",
    "                                         reg_alpha=0.09980125949843345,\n",
    "                                         boosting_type='gbdt',\n",
    "                                         reg_lambda=0.45277624619552903,\n",
    "                                         num_threads=2))\n",
    "]\n",
    "\n",
    "# 메타 모델 정의\n",
    "meta_model = RandomForestClassifier(n_estimators=100,\n",
    "                                    max_features='log2',\n",
    "                                    max_depth=10,\n",
    "                                    min_samples_split=19,\n",
    "                                    min_samples_leaf=11,\n",
    "                                    bootstrap=True,\n",
    "                                    criterion='gini',\n",
    "                                    n_jobs=-1,\n",
    "                                    random_state=42)\n",
    "\n",
    "# KFold 교차 검증 준비\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "num_samples = reshaped_input_train.shape[0]\n",
    "num_base_models = len(base_models)\n",
    "num_outputs = reshaped_output_train.shape[1]\n",
    "num_meta_features = num_base_models * num_outputs\n",
    "\n",
    "# 메타 특성 배열 초기화 (샘플 수 x (기본 모델 수 * 출력 수))\n",
    "meta_features = np.zeros((num_samples, num_meta_features))\n",
    "\n",
    "for i, model in enumerate(base_models):\n",
    "    probas = cross_val_predict(model, reshaped_input_train, reshaped_output_train, cv=kf, method='predict_proba')\n",
    "    \n",
    "    # 각 출력별 긍정 클래스의 확률을 메타 특성으로 사용\n",
    "    for output_index in range(reshaped_output_train.shape[1]):  # 출력별로 반복\n",
    "        # output_index번째 출력에 대한 긍정 클래스 확률\n",
    "        meta_features[:, i*reshaped_output_train.shape[1] + output_index] = probas[output_index][:, 1]\n",
    "# 메타 모델 학습\n",
    "meta_model.fit(meta_features, reshaped_output_train)\n",
    "\n",
    "# 테스트 데이터에 대해 메타 특성 생성\n",
    "test_meta_features = np.zeros((reshaped_input_test.shape[0], len(base_models)))\n",
    "for i, model in enumerate(base_models):\n",
    "    model.fit(reshaped_input_train, reshaped_output_train)  # 전체 데이터에 대해 기본 모델 학습\n",
    "    test_meta_features[:, i] = model.predict_proba(reshaped_input_test)[:, 1]\n",
    "\n",
    "# 메타 모델을 사용하여 최종 예측\n",
    "final_predictions = meta_model.predict(test_meta_features)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b4b0c4f5-9c67-47bf-837d-e8a82d913beb",
   "metadata": {},
   "source": [
    "display(pd.DataFrame(predict_value_xg, columns=[1,2,3,4,5,6,7]),\n",
    "        pd.DataFrame(predict_value_rf, columns=[1,2,3,4,5,6,7]))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
